{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 서비스 지표 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 환경 탐지 (GPU, NPU-FuriosaAI RNGD)\n",
    "\n",
    "- 서비스 실행 (예: 번역 + 모니터링)\n",
    "\n",
    "- 스코어 계산하기 \n",
    "\n",
    "- 리더보드에 자동 업데이트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./configuration/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations Loaded Successfully:\n",
      "Active Metrics: ['BLEU', 'METEOR', 'BERTScore', 'tps']\n",
      "Device Config: {'type': 'NPU', 'model': 'RNGD', 'count': 1}\n",
      "Model Config: {'name': 'llama3.1-8B-Instruct', 'quantization': 'W8A8', 'calibration': 'base'}\n",
      "Evaluation Settings: {'task': 'translation', 'output_dir': './results/translation'}\n",
      "----------------------- \n",
      "\n",
      "Result file already exists at: ./results/translation/Korean2English/NPU-RNGD_llama3.1-8B-Instruct-W8A8_calib-base.json. Skipping computation.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from src.common.load_config import load_all_configurations\n",
    "import os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load configuration\n",
    "all_configs = load_all_configurations(config_path)\n",
    "\n",
    "# Set ENABLE_MONITORING=true in the environment to enable monitoring\n",
    "os.environ[\"ENABLE_MONITORING\"] = \"true\" if \"power_consumption\" in all_configs[\"active_metrics\"] else \"false\"\n",
    "    \n",
    "# Print the loaded configurations\n",
    "print(\"Configurations Loaded Successfully:\")\n",
    "print(\"Active Metrics:\", all_configs[\"active_metrics\"])\n",
    "print(\"Device Config:\", all_configs[\"device_config\"])\n",
    "print(\"Model Config:\", all_configs[\"model_config\"])\n",
    "print(\"Evaluation Settings:\", all_configs[\"evaluation_settings\"])\n",
    "\n",
    "# Look up imtermediate result folder to avoid redundancy (performance leaderboard)\n",
    "name_config = (\n",
    "    f'{all_configs[\"device_config\"][\"type\"]}-'\n",
    "    f'{all_configs[\"device_config\"][\"model\"]}_'\n",
    "    f'{all_configs[\"model_config\"][\"name\"]}-'\n",
    "    f'{all_configs[\"model_config\"][\"quantization\"]}_'\n",
    "    f'calib-{all_configs[\"model_config\"].get(\"calibration\", \"none\")}'\n",
    ")\n",
    "result_folder = os.path.join(all_configs[\"evaluation_settings\"][\"output_dir\"], \"Korean2English\")\n",
    "result_file = os.path.join(result_folder, f\"{name_config}.json\")\n",
    "\n",
    "# Ensure result folder exists\n",
    "os.makedirs(result_folder, exist_ok=True)\n",
    "\n",
    "print(\"----------------------- \\n\")\n",
    "if os.path.exists(result_file):\n",
    "    print(f\"Result file already exists at: {result_file}. Skipping computation.\")\n",
    "    proceed_calc = \"true\"\n",
    "else:\n",
    "    print(f\"Result file does not exist. Proceeding with computation...\")\n",
    "    proceed_calc = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load task-specific modules based on the configuration\n",
    "task = all_configs[\"evaluation_settings\"].get(\"task\")\n",
    "\n",
    "if task == \"translation\":\n",
    "    from src.translation.one_translate import (\n",
    "        initialize_translation_environment,\n",
    "        translate_text,\n",
    "        batch_translate_text,\n",
    "    )\n",
    "    from src.metrics.evaluate_translation import evaluate_translation\n",
    "elif task == \"summarization\":\n",
    "    from src.summarization.one_summary import (\n",
    "        initialize_summarization_environment,\n",
    "        summarize_text,\n",
    "        batch_summarize_text,\n",
    "    )\n",
    "    from src.metrics.evaluate_summarization import evaluate_summarization\n",
    "elif task == \"multimodal\":\n",
    "    from src.multimodal.one_multimodal import (\n",
    "        initialize_multimodal_environment,\n",
    "        process_multimodal_data,\n",
    "    )\n",
    "    from src.metrics.evaluate_multimodal import evaluate_multimodal\n",
    "elif task == \"chatbot\":\n",
    "    from src.chatbot.one_chatbot import (\n",
    "        initialize_chatbot_environment,\n",
    "        generate_chat_response,\n",
    "    )\n",
    "    from src.metrics.evaluate_chatbot import evaluate_chatbot\n",
    "else:\n",
    "    raise ValueError(f\"Undetermined task: {task}. Please check your configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 벤치마킹 데이터셋 (FLORES-200)\n",
    "\n",
    "- 한 -> 영, 영 -> 한 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "def load_text_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.strip() for line in lines]\n",
    "\n",
    "# FLORES-200 데이터 위치 \n",
    "data_dir = \"./data/translation/flores\"\n",
    "\n",
    "data_eng = load_text_file(f\"{data_dir}/devtest.eng_Latn\")\n",
    "data_kor = load_text_file(f\"{data_dir}/devtest.kor_Hang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 06:53:32,680 - ERROR - Failed to detect NPUs: [Errno 2] No such file or directory: 'furiosa-smi'\n",
      "2025-01-09 06:53:32,681 - INFO - Translation environment detected: GPU. Using GPU for translations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 06:53:57,995 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:02,329 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:05,155 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:11,222 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:15,049 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:17,992 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:19,483 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:22,646 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:24,841 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:26,460 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:29,130 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:32,030 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:35,281 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:38,665 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:41,861 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:46,099 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:50,230 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:53,064 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:54:57,340 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:04,428 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:06,311 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:08,142 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:11,549 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:15,793 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:18,375 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:20,402 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:22,425 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:25,713 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:28,277 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:29,769 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:33,930 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:38,811 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:41,887 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:45,209 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:46,706 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:49,149 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:51,152 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:53,610 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:55,730 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:57,042 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:55:59,596 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:02,224 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:06,937 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:09,586 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:11,946 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:15,147 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:18,341 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:20,619 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:22,717 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:25,557 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:27,326 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:30,151 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:32,525 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:34,963 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:38,962 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:42,523 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:46,416 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:49,451 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:51,810 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:53,132 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:55,399 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:57,165 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:56:59,817 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:02,670 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:06,293 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:09,686 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:12,450 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:15,295 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:18,222 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:21,145 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:23,169 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:27,734 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:31,369 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:35,387 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:38,748 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:42,584 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:46,723 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:49,219 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:50,296 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:53,464 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:55,746 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:57:57,732 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:00,109 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:03,322 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:04,970 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:07,069 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:10,940 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:13,438 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:15,551 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:18,644 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:21,652 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:23,589 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:26,608 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:27,916 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:30,469 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:32,698 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:34,769 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:37,672 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:40,048 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:43,071 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ko2en translation done\n",
      "Results saved to ./results/translation/Korean2English/GPU-A5000_qwen2.5:72b-Q4_K_M_calib-base.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 06:58:45,736 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:50,987 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:58:56,475 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:59:05,247 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:59:11,010 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:59:22,216 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:59:23,936 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:59:29,435 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:59:32,654 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:59:35,337 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:59:40,538 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:59:44,819 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:59:48,412 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:59:53,310 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 06:59:58,877 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 07:00:05,600 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 07:00:11,583 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 07:00:16,207 - INFO - HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpx/_transports/default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpcore/_backends/sync.py:124\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    123\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {socket\u001b[38;5;241m.\u001b[39mtimeout: ReadTimeout, \u001b[38;5;167;01mOSError\u001b[39;00m: ReadError}\n\u001b[0;32m--> 124\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettimeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 영 -> 한 번역 \u001b[39;00m\n\u001b[1;32m     23\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 24\u001b[0m batch_results \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_translate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_eng\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_benchmark\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_language\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnglish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_language\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKorean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m batch_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melapsed_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m start_time  \u001b[38;5;66;03m# Add elapsed time to the results\u001b[39;00m\n\u001b[1;32m     26\u001b[0m result_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(all_configs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_settings\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnglish2Korean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/home/dudaji/Jun/npu-service-zoo/src/translation/one_translate.py:82\u001b[0m, in \u001b[0;36mbatch_translate_text\u001b[0;34m(input_texts, source_language, target_language)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m input_texts:\n\u001b[1;32m     81\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 82\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_language\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_language\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_language\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_language\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     elapsed_time \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     85\u001b[0m     translations\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslation\u001b[39m\u001b[38;5;124m\"\u001b[39m: result,\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melapsed_time\u001b[39m\u001b[38;5;124m\"\u001b[39m: elapsed_time\n\u001b[1;32m     88\u001b[0m     })\n",
      "File \u001b[0;32m/data/home/dudaji/Jun/npu-service-zoo/src/translation/one_translate.py:64\u001b[0m, in \u001b[0;36mtranslate_text\u001b[0;34m(input_text, source_language, target_language)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _translation_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslation environment not initialized. Call initialize_translation_environment first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_translation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_language\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_language\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/home/dudaji/Jun/npu-service-zoo/src/common/monitoring.py:22\u001b[0m, in \u001b[0;36mmonitor_power.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m _monitoring_enabled \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_MONITORING\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _monitoring_enabled:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Detect devices for monitoring\u001b[39;00m\n\u001b[1;32m     25\u001b[0m devices \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_devices\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[0;32m/data/home/dudaji/Jun/npu-service-zoo/src/translation/one_translate.py:31\u001b[0m, in \u001b[0;36minitialize_translation_environment.<locals>.<lambda>\u001b[0;34m(text, src, tgt)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _environment \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m translate_with_gpu\n\u001b[0;32m---> 31\u001b[0m     _translation_function \u001b[38;5;241m=\u001b[39m monitor_power(\u001b[38;5;28;01mlambda\u001b[39;00m text, src, tgt: \u001b[43mtranslate_with_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_model\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     32\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslation environment detected: GPU. Using GPU for translations.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _environment \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuriosa\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/data/home/dudaji/Jun/npu-service-zoo/src/translation/gpu.py:61\u001b[0m, in \u001b[0;36mtranslate_with_gpu\u001b[0;34m(source_text, source_lang, target_lang, llm_model)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Format the prompt and generate the translation\u001b[39;00m\n\u001b[1;32m     56\u001b[0m full_prompt \u001b[38;5;241m=\u001b[39m translation_prompt\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     57\u001b[0m     source_lang\u001b[38;5;241m=\u001b[39msource_lang, \n\u001b[1;32m     58\u001b[0m     target_lang\u001b[38;5;241m=\u001b[39mtarget_lang, \n\u001b[1;32m     59\u001b[0m     source_text\u001b[38;5;241m=\u001b[39msource_text\n\u001b[1;32m     60\u001b[0m )\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgpu_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:265\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    258\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[1;32m    259\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    263\u001b[0m )\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py:431\u001b[0m, in \u001b[0;36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    423\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    424\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m     },\n\u001b[1;32m    429\u001b[0m )\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    433\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[1;32m    434\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    435\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[1;32m    436\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[1;32m    437\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/llama_index/llms/ollama/base.py:261\u001b[0m, in \u001b[0;36mOllama.complete\u001b[0;34m(self, prompt, formatted, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m     payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mClient(timeout\u001b[38;5;241m=\u001b[39mTimeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_timeout)) \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[0;32m--> 261\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/api/generate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    266\u001b[0m     raw \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpx/_client.py:1145\u001b[0m, in \u001b[0;36mClient.post\u001b[0;34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1126\u001b[0m     url: URLTypes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     extensions: RequestExtensions \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;124;03m    Send a `POST` request.\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \n\u001b[1;32m   1143\u001b[0m \u001b[38;5;124;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpx/_client.py:827\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    812\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    814\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    815\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    816\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    825\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    826\u001b[0m )\n\u001b[0;32m--> 827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpx/_transports/default.py:232\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(request\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[0;32m--> 232\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    156\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/miniconda3/envs/langserve/lib/python3.11/site-packages/httpx/_transports/default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: timed out"
     ]
    }
   ],
   "source": [
    "# Initialize the translation environment\n",
    "try:\n",
    "    initialize_translation_environment(llm_model=all_configs[\"model_config\"][\"name\"])\n",
    "except EnvironmentError as e:\n",
    "    print(f\"Failed to initialize translation environment: {e}\")\n",
    "    exit(1)\n",
    "    \n",
    "# 한 -> 영 번역 \n",
    "num_benchmark = 100\n",
    "start_time = time() # start time\n",
    "batch_results = batch_translate_text(data_kor[:num_benchmark], source_language=\"Korean\", target_language=\"English\")\n",
    "batch_results[\"elapsed_time\"] = time() - start_time  # Add elapsed time to the results\n",
    "result_folder = os.path.join(all_configs[\"evaluation_settings\"][\"output_dir\"], \"Korean2English\")\n",
    "result_file = os.path.join(result_folder, f\"{name_config}.json\")\n",
    "print('ko2en translation done')\n",
    "\n",
    "# Save intermediate result \n",
    "with open(result_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(batch_results, file, indent=4, ensure_ascii=False)  # Save the batch results in JSON format\n",
    "    print(f\"Results saved to {result_file}.\")\n",
    "    \n",
    "# 영 -> 한 번역 \n",
    "start_time = time()\n",
    "batch_results = batch_translate_text(data_eng[:num_benchmark], source_language=\"English\", target_language=\"Korean\")\n",
    "batch_results[\"elapsed_time\"] = time() - start_time  # Add elapsed time to the results\n",
    "result_folder = os.path.join(all_configs[\"evaluation_settings\"][\"output_dir\"], \"English2Korean\")\n",
    "result_file = os.path.join(result_folder, f\"{name_config}.json\")\n",
    "print('en2ko translation done')\n",
    "\n",
    "# Save intermediate result \n",
    "with open(result_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(batch_results, file, indent=4, ensure_ascii=False)  # Save the batch results in JSON format\n",
    "    print(f\"Results saved to {result_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device-type</th>\n",
       "      <th>device-name</th>\n",
       "      <th>llm</th>\n",
       "      <th>quantization</th>\n",
       "      <th>calibration</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore</th>\n",
       "      <th>tps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPU</td>\n",
       "      <td>A5000</td>\n",
       "      <td>llama3.1</td>\n",
       "      <td>Q4_K_M</td>\n",
       "      <td>base</td>\n",
       "      <td>0.206346</td>\n",
       "      <td>0.560355</td>\n",
       "      <td>0.848896</td>\n",
       "      <td>52.091613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPU</td>\n",
       "      <td>A5000</td>\n",
       "      <td>llama3.3:70b</td>\n",
       "      <td>Q4_K_M</td>\n",
       "      <td>base</td>\n",
       "      <td>0.262889</td>\n",
       "      <td>0.625706</td>\n",
       "      <td>0.879954</td>\n",
       "      <td>10.143561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPU</td>\n",
       "      <td>A5000</td>\n",
       "      <td>llama3.1:70b</td>\n",
       "      <td>Q4_K_M</td>\n",
       "      <td>base</td>\n",
       "      <td>0.254576</td>\n",
       "      <td>0.606528</td>\n",
       "      <td>0.874383</td>\n",
       "      <td>10.861105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPU</td>\n",
       "      <td>A5000</td>\n",
       "      <td>qwen2:72b</td>\n",
       "      <td>Q4_K_M</td>\n",
       "      <td>base</td>\n",
       "      <td>0.241575</td>\n",
       "      <td>0.608767</td>\n",
       "      <td>0.872418</td>\n",
       "      <td>10.256634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPU</td>\n",
       "      <td>A100</td>\n",
       "      <td>llama3.1:latest</td>\n",
       "      <td>Q4_K_M</td>\n",
       "      <td>base</td>\n",
       "      <td>0.201274</td>\n",
       "      <td>0.555541</td>\n",
       "      <td>0.847286</td>\n",
       "      <td>81.697210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GPU</td>\n",
       "      <td>A100</td>\n",
       "      <td>llama3.1:70b</td>\n",
       "      <td>Q4_K_M</td>\n",
       "      <td>base</td>\n",
       "      <td>0.250461</td>\n",
       "      <td>0.604116</td>\n",
       "      <td>0.874396</td>\n",
       "      <td>18.985956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPU</td>\n",
       "      <td>A100</td>\n",
       "      <td>qwen2.5:72b</td>\n",
       "      <td>Q4_K_M</td>\n",
       "      <td>base</td>\n",
       "      <td>0.271871</td>\n",
       "      <td>0.629202</td>\n",
       "      <td>0.879257</td>\n",
       "      <td>15.049937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  device-type device-name              llm quantization calibration      BLEU  \\\n",
       "0         GPU       A5000         llama3.1       Q4_K_M        base  0.206346   \n",
       "1         GPU       A5000     llama3.3:70b       Q4_K_M        base  0.262889   \n",
       "2         GPU       A5000     llama3.1:70b       Q4_K_M        base  0.254576   \n",
       "3         GPU       A5000        qwen2:72b       Q4_K_M        base  0.241575   \n",
       "4         GPU        A100  llama3.1:latest       Q4_K_M        base  0.201274   \n",
       "5         GPU        A100     llama3.1:70b       Q4_K_M        base  0.250461   \n",
       "6         GPU        A100      qwen2.5:72b       Q4_K_M        base  0.271871   \n",
       "\n",
       "     METEOR  BERTScore        tps  \n",
       "0  0.560355   0.848896  52.091613  \n",
       "1  0.625706   0.879954  10.143561  \n",
       "2  0.606528   0.874383  10.861105  \n",
       "3  0.608767   0.872418  10.256634  \n",
       "4  0.555541   0.847286  81.697210  \n",
       "5  0.604116   0.874396  18.985956  \n",
       "6  0.629202   0.879257  15.049937  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dudaji/miniconda3/envs/langserve/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/dudaji/miniconda3/envs/langserve/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and added GPU-A5000_qwen2.5:72b-Q4_K_M_calib-base.json to leaderboard.\n",
      "Skipping GPU-A100_qwen2.5:72b-Q4_K_M_calib-base.json, already in leaderboard.\n",
      "Processed and added NPU-RNGD_llama3.1-8B-Instruct-W8A8_calib-base.json to leaderboard.\n",
      "Skipping GPU-A5000_qwen2:72b-Q4_K_M_calib-base.json, already in leaderboard.\n",
      "Skipping GPU-A100_llama3.1:latest-Q4_K_M_calib-base.json, already in leaderboard.\n",
      "Skipping GPU-A5000_llama3.1:70b-Q4_K_M_calib-base.json, already in leaderboard.\n",
      "Skipping GPU-A100_llama3.1:70b-Q4_K_M_calib-base.json, already in leaderboard.\n",
      "Skipping GPU-A5000_llama3.3:70b-Q4_K_M_calib-base.json, already in leaderboard.\n",
      "Skipping GPU-A5000_llama3.1-Q4_K_M_calib-base.json, already in leaderboard.\n",
      "Leaderboard updated and saved to ./results/translation/Korean2English/leaderboard.csv\n"
     ]
    }
   ],
   "source": [
    "from src.metrics.evaluate_translation import evaluate_translation\n",
    "\n",
    "# Configurations\n",
    "source_lang = \"Korean\"  # 소스 언어\n",
    "target_lang = \"English\"  # 목표 언어\n",
    "translation_config = f'{source_lang}2{target_lang}'\n",
    "\n",
    "result_dir = f\"./results/translation/{translation_config}/\"\n",
    "leaderboard_file = f\"./results/translation/{translation_config}/leaderboard.csv\"\n",
    "\n",
    "# 기존 리더보드 파일 로드 또는 새로 생성\n",
    "if os.path.exists(leaderboard_file):\n",
    "    leaderboard = pd.read_csv(leaderboard_file)\n",
    "else:\n",
    "    leaderboard = pd.DataFrame(columns=[\n",
    "        \"device-type\", \"device-name\", \"llm\", \"quantization\", \"calibration\",\n",
    "        \"BLEU\", \"METEOR\", \"BERTScore\", \"tps\"\n",
    "    ])\n",
    "    \n",
    "# Process each JSON file\n",
    "for filename in os.listdir(result_dir):\n",
    "    if not filename.endswith(\".json\"):\n",
    "        continue\n",
    "\n",
    "    # Parse metadata from filename\n",
    "    name_head = filename.replace(\".json\", \"\")\n",
    "    metadata = {\n",
    "        \"device-type\": name_head.split(\"-\")[0],\n",
    "        \"device-name\": name_head.split(\"_\")[0].split(\"-\")[1],\n",
    "        \"llm\": name_head.split(\"_\")[1].split('-')[0],\n",
    "        \"quantization\": name_head.split(\"_calib\")[0].split('-')[-1],\n",
    "        \"calibration\": name_head.split(\"_calib-\")[1],\n",
    "    }\n",
    "\n",
    "    # Skip if already in leaderboard\n",
    "    if ((leaderboard[\"device-type\"] == metadata[\"device-type\"]) &\n",
    "        (leaderboard[\"device-name\"] == metadata[\"device-name\"]) &\n",
    "        (leaderboard[\"llm\"] == metadata[\"llm\"]) &\n",
    "        (leaderboard[\"quantization\"] == metadata[\"quantization\"]) &\n",
    "        (leaderboard[\"calibration\"] == metadata[\"calibration\"])).any():\n",
    "        print(f\"Skipping {filename}, already in leaderboard.\")\n",
    "        continue\n",
    "    \n",
    "    # Load translation results\n",
    "    with open(os.path.join(result_dir, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "        json_data = json.load(file)\n",
    "        translations = json_data.get(\"translations\", [])\n",
    "\n",
    "    # Evaluate translations\n",
    "    num_metrics = 4  # BLEU, METEOR, BERTScore, TPS\n",
    "    metrics = np.full((num_metrics, len(translations)), np.nan)\n",
    "\n",
    "    for i, result in enumerate(translations):\n",
    "        translation = result.get(\"translation\", \"\")\n",
    "        elapsed_time = result.get(\"elapsed_time\", 1e-6)  # Default time if not provided\n",
    "        ref_text = data_eng[i] if i < len(data_eng) else \"\"\n",
    "\n",
    "        # Evaluate translation\n",
    "        metric_result = evaluate_translation(\n",
    "            translation, ref_text, target_lang, elapsed_time, all_configs[\"active_metrics\"]\n",
    "        )\n",
    "        for j, metric_name in enumerate(all_configs[\"active_metrics\"]):\n",
    "            metrics[j, i] = metric_result.get(metric_name, np.nan)\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_metrics = {metric: np.nanmean(metrics[j, :]) for j, metric in enumerate(all_configs[\"active_metrics\"])}\n",
    "\n",
    "    # Add to leaderboard\n",
    "    new_entry = pd.DataFrame([{\n",
    "        **metadata,\n",
    "        **avg_metrics\n",
    "    }])  # Create a DataFrame for the new entry\n",
    "\n",
    "    # Concatenate the new entry to the leaderboard\n",
    "    leaderboard = pd.concat([leaderboard, new_entry], ignore_index=True)\n",
    "    print(f\"Processed and added {filename} to leaderboard.\")\n",
    "\n",
    "# 리더보드 CSV 파일로 저장\n",
    "leaderboard.to_csv(leaderboard_file, index=False)\n",
    "print(f\"Leaderboard updated and saved to {leaderboard_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping GPU-A100_qwen2.5:72b-Q4_K_M_calib-base.json, already in leaderboard.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dudaji/miniconda3/envs/langserve/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and added NPU-RNGD_llama3.1-8B-Instruct-W8A8_calib-base.json to leaderboard.\n",
      "Skipping GPU-A5000_qwen2:72b-Q4_K_M_calib-base.json, already in leaderboard.\n",
      "Skipping GPU-A100_llama3.1:latest-Q4_K_M_calib-base.json, already in leaderboard.\n",
      "Skipping GPU-A5000_llama3.1:70b-Q4_K_M_calib-base.json, already in leaderboard.\n",
      "Skipping GPU-A100_llama3.1:70b-Q4_K_M_calib-base.json, already in leaderboard.\n",
      "Skipping GPU-A5000_llama3.3:70b-Q4_K_M_calib-base.json, already in leaderboard.\n",
      "Skipping GPU-A5000_llama3.1-Q4_K_M_calib-base.json, already in leaderboard.\n",
      "Leaderboard updated and saved to ./results/translation/English2Korean/leaderboard.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configurations\n",
    "source_lang = \"English\"  # 소스 언어\n",
    "target_lang = \"Korean\"  # 목표 언어\n",
    "translation_config = f'{source_lang}2{target_lang}'\n",
    "\n",
    "result_dir = f\"./results/translation/{translation_config}/\"\n",
    "leaderboard_file = f\"./results/translation/{translation_config}/leaderboard.csv\"\n",
    "\n",
    "# 기존 리더보드 파일 로드 또는 새로 생성\n",
    "if os.path.exists(leaderboard_file):\n",
    "    leaderboard = pd.read_csv(leaderboard_file)\n",
    "else:\n",
    "    leaderboard = pd.DataFrame(columns=[\n",
    "        \"device-type\", \"device-name\", \"llm\", \"quantization\", \"calibration\",\n",
    "        \"BLEU\", \"METEOR\", \"BERTScore\", \"tps\"\n",
    "    ])\n",
    "    \n",
    "# Process each JSON file\n",
    "for filename in os.listdir(result_dir):\n",
    "    if not filename.endswith(\".json\"):\n",
    "        continue\n",
    "\n",
    "    # Parse metadata from filename\n",
    "    name_head = filename.replace(\".json\", \"\")\n",
    "    metadata = {\n",
    "        \"device-type\": name_head.split(\"-\")[0],\n",
    "        \"device-name\": name_head.split(\"_\")[0].split(\"-\")[1],\n",
    "        \"llm\": name_head.split(\"_\")[1].split('-')[0],\n",
    "        \"quantization\": name_head.split(\"_calib\")[0].split('-')[-1],\n",
    "        \"calibration\": name_head.split(\"_calib-\")[1],\n",
    "    }\n",
    "\n",
    "    # Skip if already in leaderboard\n",
    "    if ((leaderboard[\"device-type\"] == metadata[\"device-type\"]) &\n",
    "        (leaderboard[\"device-name\"] == metadata[\"device-name\"]) &\n",
    "        (leaderboard[\"llm\"] == metadata[\"llm\"]) &\n",
    "        (leaderboard[\"quantization\"] == metadata[\"quantization\"]) &\n",
    "        (leaderboard[\"calibration\"] == metadata[\"calibration\"])).any():\n",
    "        print(f\"Skipping {filename}, already in leaderboard.\")\n",
    "        continue\n",
    "    \n",
    "    # Load translation results\n",
    "    with open(os.path.join(result_dir, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "        json_data = json.load(file)\n",
    "        translations = json_data.get(\"translations\", [])\n",
    "\n",
    "    # Evaluate translations\n",
    "    num_metrics = 4  # BLEU, METEOR, BERTScore, TPS\n",
    "    metrics = np.full((num_metrics, len(translations)), np.nan)\n",
    "\n",
    "    for i, result in enumerate(translations):\n",
    "        translation = result.get(\"translation\", \"\")\n",
    "        elapsed_time = result.get(\"elapsed_time\", 1e-6)  # Default time if not provided\n",
    "        ref_text = data_kor[i] if i < len(data_kor) else \"\"\n",
    "\n",
    "        # Evaluate translation\n",
    "        metric_result = evaluate_translation(\n",
    "            translation, ref_text, target_lang, elapsed_time, all_configs[\"active_metrics\"]\n",
    "        )\n",
    "        for j, metric_name in enumerate(all_configs[\"active_metrics\"]):\n",
    "            metrics[j, i] = metric_result.get(metric_name, np.nan)\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_metrics = {metric: np.nanmean(metrics[j, :]) for j, metric in enumerate(all_configs[\"active_metrics\"])}\n",
    "\n",
    "    # Add to leaderboard\n",
    "    new_entry = pd.DataFrame([{\n",
    "        **metadata,\n",
    "        **avg_metrics\n",
    "    }])  # Create a DataFrame for the new entry\n",
    "\n",
    "    # Concatenate the new entry to the leaderboard\n",
    "    leaderboard = pd.concat([leaderboard, new_entry], ignore_index=True)\n",
    "    print(f\"Processed and added {filename} to leaderboard.\")\n",
    "\n",
    "# 리더보드 CSV 파일로 저장\n",
    "leaderboard.to_csv(leaderboard_file, index=False)\n",
    "print(f\"Leaderboard updated and saved to {leaderboard_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langserve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
